<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<html>
<head>
    {% if title %}
    <title>{{ title }} - Frozen in Time</title>
    {% else %}
    <title>Frozen in Time</title>
    {% endif %}
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
    <meta property="og:image" content="Path to my teaser.png"/>
    <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
    <meta property="og:title" content="Creative and Descriptive Paper Title."/>
    <meta property="og:description" content="Paper description."/>
    <!-- Get from Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src=""></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());
        gtag('config', 'UA-75863369-6');
        var delayTimer;

        function liveSearch(value, topk) {
            clearTimeout(delayTimer)
            delayTimer = setTimeout(function () {
                value = value.trim(); // remove any spaces around the text
                if (value != "") { // don't make requests with an empty string
                    $.ajax({
                        url: "query",
                        data: {query: value, topk: topk},
                        dataType: "json",
                        success: function (data) {
                            var res = "";
                            // create the html with results
                            var datarows = []
                            ncols = 4
                            while (data.length > 0) {
                                datarows.push(data.splice(0, ncols));
                            }

                            for (i in datarows) {
                                res += "<tr>"
                                for (j in datarows[i]) {
                                    vid_url = "https://ak.picdn.net/shutterstock/videos/" + datarows[i][j].relurl
                                    similarity = datarows[i][j].similarity
                                    curr_ele = "<th><div>" +
                                        "<video height='140' autoplay muted loop>" +
                                        "<source src=" + "'" + vid_url + "'" + " type='video/mp4'>" +
                                        "Your browser does not support the video tag. </video><p>" + similarity + "</p></div></th>"
                                    res += curr_ele
                                }
                                res += "</tr>"
                            }
                            console.log(res)
                            $("#results").html(res);
                        }
                    });
                } else {
                    $("#results").html(""); // set the results empty in case of empty string
                }
            }, 500)
        }

        function ReadMore() {
            var dots = document.getElementById("dots");
            var moreText = document.getElementById("more");
            var btnText = document.getElementById("readmrBtn");

            if (dots.style.display === "none") {
                dots.style.display = "inline";
                btnText.innerHTML = "+";
                moreText.style.display = "none";
            } else {
                dots.style.display = "none";
                btnText.innerHTML = "-";
                moreText.style.display = "inline";
            }
        }
    </script>
</head>
<body>
<div width="800px">
    Frozen in Time ❄️️️️️⏳
    <span align="right">
        <a href="#abstract">Abstract</a>
        <a href="#demo">Demo</a>
        <a href="#paper">Paper</a>
        <a href="#dataset">Dataset</a>
    </span>
</div>

<hr>
<br>

<h1 align="center">Frozen in Time: ️<br> A Joint Video and Image Encoder for End to End Retrieval</h1>
<table align=center width=600px>
    <table align=center width=600px>
        <tr>
            <td align=center width=80px>

                <span style="font-size:18px"><a href="http://maxbain.com/">Max Bain</a></span>

            </td>
            <td align=center width=100px>

                <span style="font-size:18px"><a href="https://a-nagrani.github.io/">Arsha Nagrani</a></span>

            </td>
            <td align=center width=100px>

                <span style="font-size:18px"><a href="http://imagine.enpc.fr/~varolg/">Gül Varol</a></span>

            </td>
            <td align=center width=100px>

                <span style="font-size:18px"><a href="https://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a></span>

            </td>
        </tr>
    </table>
    <table align=center width=250px>
        <tr>
            <td align=center width=120px>

                <span style="font-size:24px"><a href=''>[Paper]</a></span>

            </td>
            <td align=center width=120px>

                <span style="font-size:24px"><a href='https://github.com/richzhang/webpage-template'>[GitHub]</a></span><br>

            </td>
        </tr>
    </table>
</table>


<table align=center width=850px>
    <tr>
        <td width=260px>

            <img class="round" style="width:800px" src="static/resources/arch.png"/>

        </td>
    </tr>
</table>

<hr>

<table align=center width=850px id="abstract">
    <h1 align=center>Abstract</h1>
    <tr>
        <td>
            <p>
                Our objective in this work is video-text retrieval - in particular a joint embedding that enables
                efficient text-to-video retrieval. The challenges in this area include the design of the visual
                architecture and the nature of the training data, in that the available large scale video-text training
                datasets, such as HowTo100M, are noisy and hence competitive performance is achieved only at scale
                through large amounts of compute. We address both these challenges in this paper.<span
                    id="dots">...</span><span id="more">We propose an end-to-end trainable model that is designed to take advantage of both large-scale image and video captioning datasets. Our model is an adaptation and extension of the recent ViT and Timesformer architectures, and consists of attention in both space and time. The model is flexible and can be trained on both image and video text datasets, either independently or in conjunction. It is trained with a curriculum learning schedule that begins by treating images as 'frozen' snapshots of video, and then gradually learns to attend to increasing temporal context when trained on video datasets. We also provide a new video-text pretraining dataset WebVid-2M, comprised of over two million videos with weak captions scraped from the internet. Despite training on datasets that are an order of magnitude smaller, we show that this approach yields state-of-the-art results on standard downstream video-retrieval benchmarks including MSR-VTT, MSVD, DiDeMo and LSMDC.</span>
            </p>
            <div align="center">
                <button onclick="ReadMore()" id="readmrBtn"> +</button>
            </div>
        </td>
    </tr>
</table>

<hr>

<table align=center width=850px id="demo">
    <h1 align=center>Real-Time Video Search Demo</h1>
    <tr>
        <td>
            <form align="center">
                <input type="text" onkeyup="liveSearch(this.value, topk.value)" placeholder="Enter your search term..."
                       style='font-size: 20px;' size="50">
                <label for="topk"> max display:</label>
                <select name="topk" id="topk" style='font-size: 20px;'>
                    <option value=4>4</option>
                    <option value=8>8</option>
                    <option value=16>16</option>
                </select>
            </form>
            <br>
            <table id="results"></table>
        </td>
    </tr>
</table>


<hr>
<!--<h1 align=center>Talk</h1>
<p align="center">
    <iframe width="660" height="395" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
</p>

<table align=center width=800px>
    <br>
    <tr>

            <span style="font-size:28px"><a href=''>[Slides]</a>
            </span>

    </tr>
</table>
<hr>
-->

<table align=center width=450px id="paper">
    <h1 align=center>Paper</h1>
    <tr>
        <td><a href=""><img class="layered-paper-big" style="height:175px" src="static/resources/paper.png"/></a></td>
        <td><span style="font-size:14pt">M. Bain, A. Nagrani, G. Varol, A. Zisserman.<br>
				<b>Frozen in Time: A Joint Video and Image Encoder for End to End Paper.</b><br>
				ICCV, 2021.<br>
				(hosted on <a href="https://arxiv.org/abs/2104.00650">ArXiv</a>)<br>
            <!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				</span>
        </td>
    </tr>
</table>
<br>

<table align=center width=600px>
    <tr>
        <td align="">
            <div align="center">
                <a onclick="if (document.getElementById(&quot;BIBBain21&quot;).style.display==&quot;none&quot;) document.getElementById(&quot;BIBBain21&quot;).style.display=&quot;block&quot;; else document.getElementById(&quot;BIBBain21&quot;).style.display=&quot;none&quot;;">
                    [Bibtex] </a>
            </div>
            <div style="display: none;" class="BibtexExpand" id="BIBBain21">
					<pre class="bibtex">
						@misc{bain2021frozen,
							  title={Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval},
							  author={Max Bain and Arsha Nagrani and Gül Varol and Andrew Zisserman},
							  year={2021},
							  eprint={2104.00650},
							  archivePrefix={arXiv},
							  primaryClass={cs.CV}
						}
					</pre>
            </div>
        </td>
    </tr>
</table>

<hr>
<br>


<table align=center width=800px id="dataset">
    <h1 align=center>WebVid Dataset</h1>
    <tr>
        <td>
            Some dataset info.
        </td>
    </tr>
</table>

<hr>
<br>


<table align=center width=900px>
    <tr>
        <td width=400px>
            <left>
                <h1 align=center>Acknowledgements</h1>
                This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a
                    href="http://richzhang.github.io/">Richard Zhang</a> for a <a
                    href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a
                    href="https://github.com/richzhang/webpage-template">here</a>.
            </left>
        </td>
    </tr>
</table>

<br>
</body>
</html>

